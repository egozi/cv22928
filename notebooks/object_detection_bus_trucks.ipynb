{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3r_SAMLpW_U"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]\n",
        "(https://colab.research.google.com/github/egozi/cv22928/blob/main/notebooks/object_detection_bus_trucks.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U0Of1PsKFIKw",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics\n",
        "!pip install -q kaggle\n",
        "!pip install -q seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pYq7p56NA9A0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib import patches, patheffects\n",
        "\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import cv2\n",
        "\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YlLMOp_ODCiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97882a0-f365-46c7-f2e4-d5e8ee081146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab: True\n"
          ]
        }
      ],
      "source": [
        "# Detect if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "print(f\"Running in Google Colab: {IN_COLAB}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3kl81N8jjT2x"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if IN_COLAB:\n",
        "  sys.path.append('/content/cv22928/object_detection') # Adjust this path if necessary based on how the object_detection folder is structured in Colab\n",
        "else:\n",
        "  sys.path.append('../object_detection')  # adjust path as needed\n",
        "\n",
        "from format_data import format_gt, format_model_predictions\n",
        "from pred_gt_matching import match_predictions_to_gt_greedy\n",
        "from classify_pred import process_single_class_single_image\n",
        "from vis import visualize_detection_results, create_detection_summary_plot, plot_yolo_results, draw_im\n",
        "from evaluator import ObjectDetectionEvaluator\n",
        "from data_loader import collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IpGl0MkIib0"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XYoAuZDjT2x"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    # Set up Kaggle credentials from Colab secrets\n",
        "    from google.colab import userdata\n",
        "    kaggle_username = userdata.get('KAGGLE_USERNAME')\n",
        "    kaggle_key = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "    # Step 2: Create kaggle.json file with credentials\n",
        "    kaggle_config = {\n",
        "        \"username\": kaggle_username,\n",
        "        \"key\": kaggle_key\n",
        "    }\n",
        "\n",
        "    # Create .kaggle directory and save credentials\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "    with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "        json.dump(kaggle_config, f)\n",
        "\n",
        "    DATA_PATH = \"/content/open-images-bus-trucks\"\n",
        "else:\n",
        "    # Load Kaggle credentials from local file\n",
        "    with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'r') as f:\n",
        "        creds = json.load(f)\n",
        "    kaggle_username = creds['username']\n",
        "    kaggle_key = creds['key']\n",
        "\n",
        "    DATA_PATH = \"./data/open-images-bus-trucks\"\n",
        "\n",
        "# Set environment variables (optional, for some APIs that expect them)\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_username\n",
        "os.environ['KAGGLE_KEY'] = kaggle_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEk5N1cYBmaW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Step 3: Download the Open Images Bus Trucks dataset\n",
        "# Replace with the actual dataset path from Kaggle\n",
        "dataset_name = \"sixhky/open-images-bus-trucks\"  # Adjust this to the correct dataset name\n",
        "\n",
        "print(f\"Downloading dataset: {dataset_name}\")\n",
        "!kaggle datasets download -d {dataset_name}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyiPko8-DofE"
      },
      "outputs": [],
      "source": [
        "# Step 4: Extract the downloaded zip file\n",
        "zip_filename = f\"{dataset_name.split('/')[-1]}.zip\"\n",
        "\n",
        "print(f\"Extracting {zip_filename} to {DATA_PATH}\")\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_PATH)\n",
        "\n",
        "# Step 5: List the contents of the extracted folder\n",
        "print(\"\\nDataset contents:\")\n",
        "for root, dirs, files in os.walk(DATA_PATH):\n",
        "    level = root.replace(DATA_PATH, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:10]:  # Show first 10 files\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 10:\n",
        "        print(f\"{subindent}... and {len(files) - 10} more files\")\n",
        "\n",
        "# Step 6: Clean up the zip file\n",
        "os.remove(zip_filename)\n",
        "print(f\"\\nCleaned up {zip_filename}\")\n",
        "\n",
        "print(f\"\\nDataset successfully downloaded and extracted to: {DATA_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo2crGh72OiV"
      },
      "outputs": [],
      "source": [
        "# Reading the csv\n",
        "IMAGE_ROOT = DATA_PATH + '/images'\n",
        "DF_RAW = pd.read_csv(DATA_PATH + '/df.csv')\n",
        "display(DF_RAW.head())\n",
        "print(DF_RAW.shape)\n",
        "class_names = DF_RAW['LabelName'].unique()\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHMow61xGEWU"
      },
      "source": [
        "\n",
        "\n",
        "Note that XMin, XMax, YMin, and YMax correspond to the ground truth of the bounding box of the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCSHqGrxGE33"
      },
      "outputs": [],
      "source": [
        "# create a custom dataset\n",
        "class OpenImages(Dataset):\n",
        "    def __init__(self, df, image_folder = IMAGE_ROOT):\n",
        "        self.df = df\n",
        "        self.unique_images = df['ImageID'].unique()\n",
        "        self.root = image_folder\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.unique_images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_id = self.unique_images[index]\n",
        "        image_path = f'{self.root}/images/{image_id}.jpg'\n",
        "        image = cv2.imread(image_path, 1)  # converting to RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        df = self.df.copy()\n",
        "        df = df[df['ImageID'] == image_id]  # getting the row based on the index\n",
        "        h, w, _ = image.shape\n",
        "        boxes = df['XMin,YMin,XMax,YMax'.split(',')].values\n",
        "        boxes = (boxes*np.array([w,h,w,h])).astype(np.uint16)\n",
        "        classes = df['LabelName'].values.tolist()\n",
        "\n",
        "        return image, boxes, classes, image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2XLbHUD1rvf"
      },
      "outputs": [],
      "source": [
        "ds = OpenImages(DF_RAW)\n",
        "len(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4210898"
      },
      "outputs": [],
      "source": [
        "# Randomly select 16 indices\n",
        "random_indices = np.random.choice(len(ds), 16, replace=False)\n",
        "\n",
        "# Create a figure with 4x4 subplots\n",
        "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "axes = axes.flatten() # Flatten the 2D array of axes for easy iteration\n",
        "\n",
        "# Iterate through the random indices and display the images\n",
        "for i, idx in enumerate(random_indices):\n",
        "    im, bbs, clss, _ = ds[idx]\n",
        "    draw_im(im, bbs=bbs, classes=clss, ax=axes[i], figsize=(3,3), title=idx)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40bad8ff"
      },
      "outputs": [],
      "source": [
        "# Find ImageIDs that have both 'Bus' and 'Truck' labels\n",
        "bus_truck_image_ids = DF_RAW.groupby('ImageID')['LabelName'].apply(lambda x: set(x) == {'Bus', 'Truck'})\n",
        "bus_truck_image_ids = bus_truck_image_ids[bus_truck_image_ids].index.tolist()\n",
        "\n",
        "print(f\"Found {len(bus_truck_image_ids)} images containing both buses and trucks.\")\n",
        "\n",
        "# Display the first few images (e.g., 5 images)\n",
        "num_images_to_show = min(5, len(bus_truck_image_ids))\n",
        "\n",
        "if num_images_to_show > 0:\n",
        "    fig, axes = plt.subplots(1, num_images_to_show, figsize=(15, 5))\n",
        "    if num_images_to_show == 1:\n",
        "        axes = [axes] # Make it iterable if there's only one subplot\n",
        "\n",
        "    for i in range(num_images_to_show):\n",
        "        image_id = bus_truck_image_ids[i]\n",
        "        # Find the index of this image_id in the unique_images list of the dataset\n",
        "        idx = np.where(ds.unique_images == image_id)[0][0]\n",
        "        im, bbs, clss, _ = ds[idx]\n",
        "        draw_im(im, bbs=bbs, classes=clss, ax=axes[i], title=idx)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No images found with both buses and trucks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a79776d8"
      },
      "source": [
        "Next, we'll select an image from your dataset and run the model on it. We'll then visualize the results with the detected bounding boxes and labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T4KIWZ9KV34"
      },
      "source": [
        "# process 1 image (demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2e72c21"
      },
      "outputs": [],
      "source": [
        "target_classes = ['bus', 'truck']\n",
        "evaluator = ObjectDetectionEvaluator(target_classes)\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', trust_repo=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G63mqsRMjT23"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXVrvqBVjT23"
      },
      "outputs": [],
      "source": [
        "# Select an image from your dataset (e.g., the first image)\n",
        "# We'll use image 22 from the dataset for demonstration, as it contains both Bus and Truck\n",
        "image, bbs, clss, image_path = ds[0]\n",
        "\n",
        "# run model\n",
        "results = model(image)\n",
        "\n",
        "# arrange data\n",
        "ground_truths_all = format_gt([bbs], [clss], target_classes)\n",
        "predictions_all = format_model_predictions(results, class_names)\n",
        "\n",
        "# temp - for one image\n",
        "predictions_all = predictions_all['image0.jpg']\n",
        "ground_truths_all = ground_truths_all['image0.jpg']\n",
        "\n",
        "# draw all detections and gt boxes\n",
        "plot_yolo_results(results, image, model.names, ground_truths_all)\n",
        "\n",
        "# Iterate through each target class and evaluate\n",
        "eval_results = {}\n",
        "for class_id, class_name in enumerate(target_classes):\n",
        "    # Filter predictions for the current class\n",
        "    class_predictions = [p for p in predictions_all if p['class'] == class_id]\n",
        "    print(class_predictions)\n",
        "\n",
        "    # Filter ground truths for the current class\n",
        "    class_ground_truths = [gt for gt in ground_truths_all if gt['class'] == class_id]\n",
        "\n",
        "    # pred_boxes = np.array([p['bbox'] for p in class_predictions])\n",
        "    # gt_boxes = np.array([gt['bbox'] for gt in class_ground_truths])\n",
        "\n",
        "    # iou_matrix = calculate_iou(pred_boxes, gt_boxes)\n",
        "    iou_matrix = evaluator.calculate_iou_matrix_single_class(class_predictions, class_ground_truths, class_id)\n",
        "\n",
        "    # Process this single class in this single image\n",
        "    results_per_class = process_single_class_single_image(\n",
        "        predictions=class_predictions, # Pass the filtered predictions\n",
        "        ground_truths=class_ground_truths, # Pass the filtered ground truths\n",
        "        target_class=class_id,\n",
        "        iou_matrix=iou_matrix, # Pass the class-specific IoU matrix\n",
        "        iou_threshold=0.5,\n",
        "        use_hungarian=True # Use Hungarian matching\n",
        "    )\n",
        "\n",
        "    # Visualize the results for the current class\n",
        "    # We pass the filtered ground truths for visualization\n",
        "    fig = visualize_detection_results(\n",
        "        image=image,\n",
        "        results=results_per_class,\n",
        "        ground_truths=class_ground_truths,\n",
        "        class_name=class_name,\n",
        "        iou_threshold=0.5,\n",
        "        show_confidence=True\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    eval_results[class_name] = results_per_class\n",
        "\n",
        "for i, class_name in enumerate(target_classes):\n",
        "    print(f\"\\nResults for class: {class_name}\")\n",
        "    print(f\"TP: {eval_results[class_name]['num_tp']}\")\n",
        "    print(f\"FP: {eval_results[class_name]['num_fp']}\")\n",
        "    print(f\"FN: {eval_results[class_name]['num_fn']}\")\n",
        "\n",
        "create_detection_summary_plot(eval_results, target_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9pN01koda5E"
      },
      "source": [
        "# test evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnUDmSiBep1z"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "dataset = OpenImages(DF_RAW)\n",
        "\n",
        "# Create the DataLoader\n",
        "batch_size = 4\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=4,  # Add multiprocessing for faster loading\n",
        "    pin_memory=True  # Faster GPU transfer\n",
        ")\n",
        "\n",
        "print(f\"DataLoader created with batch size: {batch_size}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiVJs3d3dEWK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "evaluator = ObjectDetectionEvaluator(class_names)\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', trust_repo=True)\n",
        "model.eval()\n",
        "\n",
        "# for batch_idx, batch in enumerate(dataloader):\n",
        "\n",
        "# Set to True to process only the first few batches for testing\n",
        "process_first_batches = True\n",
        "num_batches_to_process = 20\n",
        "\n",
        "# Loop through the DataLoader\n",
        "for batch_idx, batch in enumerate(dataloader):\n",
        "    if process_first_batches and batch_idx >= num_batches_to_process:\n",
        "        print(f\"Processed {num_batches_to_process} batches for testing.\")\n",
        "        break\n",
        "\n",
        "    images, gt_bboxes, gt_classes, images_path = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Batch inference\n",
        "        res = model(images_path)\n",
        "\n",
        "    # Format predictions for current image\n",
        "    image_predictions = format_model_predictions(res, class_names)\n",
        "    ground_truths = format_gt(gt_bboxes, gt_classes, class_names, res.files)\n",
        "\n",
        "    # Process each image in the batch\n",
        "    for inx, image_id in enumerate(res.files):\n",
        "        # image_id = images_path[i]\n",
        "\n",
        "        # Evaluate each class\n",
        "        for class_id in range(0, len(class_names)):\n",
        "            iou_matrix = evaluator.calculate_iou_matrix_single_class(\n",
        "                predictions=image_predictions[image_id],\n",
        "                ground_truths=ground_truths[image_id],\n",
        "                class_id=class_id\n",
        "            )\n",
        "\n",
        "            results = process_single_class_single_image(\n",
        "                predictions=image_predictions[image_id],\n",
        "                ground_truths=ground_truths[image_id],\n",
        "                target_class=class_id,\n",
        "                iou_matrix=iou_matrix,\n",
        "                iou_threshold=0.5,\n",
        "                use_hungarian=False\n",
        "            )\n",
        "\n",
        "            evaluator.store_results(image_id, class_id, results)\n",
        "\n",
        "    if batch_idx % 100 == 0:\n",
        "        print(f\"Processed {batch_idx + 1} batches...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi4xtkUFiSsq"
      },
      "outputs": [],
      "source": [
        "evaluator.print_evaluation_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXcFY1VsjT25"
      },
      "outputs": [],
      "source": [
        "evaluator.plot_precision_recall_curves()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0P_ClmIjT25"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6343efac",
        "outputId": "a50503cd-27f5-49dd-d26d-eb4d2c639d0c"
      },
      "source": [
        "import os\n",
        "\n",
        "print(\"Listing files and directories in the current directory:\")\n",
        "!ls -la\n",
        "\n",
        "print(\"\\nListing files and directories in /content/:\")\n",
        "!ls -la /content/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files and directories in the current directory:\n",
            "total 14488\n",
            "drwxr-xr-x 1 root root     4096 Jul 24 18:19 .\n",
            "drwxr-xr-x 1 root root     4096 Jul 24 17:54 ..\n",
            "drwxr-xr-x 4 root root     4096 Jul 23 13:39 .config\n",
            "drwxr-xr-x 5 root root     4096 Jul 24 18:03 cv22928\n",
            "drwxr-xr-x 3 root root     4096 Jul 24 18:19 open-images-bus-trucks\n",
            "drwxr-xr-x 1 root root     4096 Jul 23 13:39 sample_data\n",
            "-rw-r--r-- 1 root root 14808437 Jul 24 18:19 yolov5s.pt\n",
            "\n",
            "Listing files and directories in /content/:\n",
            "total 14488\n",
            "drwxr-xr-x 1 root root     4096 Jul 24 18:19 .\n",
            "drwxr-xr-x 1 root root     4096 Jul 24 17:54 ..\n",
            "drwxr-xr-x 4 root root     4096 Jul 23 13:39 .config\n",
            "drwxr-xr-x 5 root root     4096 Jul 24 18:03 cv22928\n",
            "drwxr-xr-x 3 root root     4096 Jul 24 18:19 open-images-bus-trucks\n",
            "drwxr-xr-x 1 root root     4096 Jul 23 13:39 sample_data\n",
            "-rw-r--r-- 1 root root 14808437 Jul 24 18:19 yolov5s.pt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}